{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14-False-1-1-mae-adam-1\n",
      "Iteration 1 of 3072\n",
      "X train (1009, 14, 1) and test (1007, 14, 1)\n",
      "Y train (1009,) and test (1007,)\n",
      "Test dates (1007,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 14, 1)             12        \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 1)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 26.0\n",
      "Trainable params: 26.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "29s - loss: 0.2125 - rmse_metric: 0.2125\n",
      "dict_keys(['rmse_metric', 'loss'])\n",
      "Reshaped predicted (1007, 1) and y_test (1007, 1)\n",
      "test_dates shape (1007,) vs y_hat shape (1007, 1) vs y_test shape (1007, 1)\n",
      "       y_hat          y\n",
      "0  39.497967  32.749279\n",
      "1  39.496887  32.568298\n",
      "2  39.498299  32.091167\n",
      "3  39.498329  31.704527\n",
      "4  39.498154  31.293207\n",
      "[[-0.3662616 ]\n",
      " [-0.36631459]\n",
      " [-0.36624545]\n",
      " [-0.3662439 ]\n",
      " [-0.36625242]]\n",
      "[[-0.69666406]\n",
      " [-0.70552452]\n",
      " [-0.72888391]\n",
      " [-0.74781307]\n",
      " [-0.76795047]]\n",
      "X train (2030, 14, 1) and test (1006, 14, 1)\n",
      "Y train (2030,) and test (1006,)\n",
      "Test dates (1006,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 14, 1)             12        \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 1)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 26.0\n",
      "Trainable params: 26.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "63s - loss: 0.2256 - rmse_metric: 0.2256\n",
      "dict_keys(['rmse_metric', 'loss'])\n",
      "Reshaped predicted (1006, 1) and y_test (1006, 1)\n",
      "test_dates shape (1006,) vs y_hat shape (1006, 1) vs y_test shape (1006, 1)\n",
      "       y_hat          y\n",
      "0  60.562485  67.964388\n",
      "1  60.569836  68.194745\n",
      "2  60.575405  67.007517\n",
      "3  60.580822  66.218985\n",
      "4  60.584408  68.239045\n",
      "[[ 0.26063687]\n",
      " [ 0.26108569]\n",
      " [ 0.2614255 ]\n",
      " [ 0.2617563 ]\n",
      " [ 0.26197505]]\n",
      "[[ 0.71248887]\n",
      " [ 0.72655115]\n",
      " [ 0.65407633]\n",
      " [ 0.60594007]\n",
      " [ 0.72925544]]\n",
      "[5.513478789957117, 4.638510750537985]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend\n",
    "import capstone_support as cs\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# The stock we are interested in\n",
    "stock_name = \"QCOM\"\n",
    "# Data set includes stock prices beginning at start_date\n",
    "stock_start_date = '2006-01-01'\n",
    "# Number of historical days (M) to use for the prediction\n",
    "# In baseline model, this is used to generate the prediction\n",
    "# In lstm, this is an input sequence\n",
    "M_historical_days = 10\n",
    "# Predict for N days ahead\n",
    "N_predict_days = 14\n",
    "# Splits to use for TimeSeriesSplit\n",
    "timeSeriesSplitCount = 10\n",
    "\n",
    "def rmse_score(predicted, true_label):\n",
    "    return math.sqrt(mean_squared_error(true_label, predicted))\n",
    "\n",
    "def rmse_metric(y, y_pred):\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y), axis=-1))\n",
    "\n",
    "def prepareLSTMModelData(stockdf, timesteps):\n",
    "    num_samples = stockdf.shape[0] - (timesteps)\n",
    "    num_features = stockdf.shape[1]\n",
    "    X = np.zeros((num_samples, timesteps, num_features))\n",
    "    y = np.zeros((num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        y_pos = i + timesteps\n",
    "        X[i] = stockdf[i:y_pos]\n",
    "        y[i] = stockdf['Adj. Close'][y_pos]\n",
    "\n",
    "    return (X, y)\n",
    "\n",
    "def validateLSTMModel(ax, df, m_days, n_days, splits, dates, \\\n",
    "                      neurons=20, num_epochs=1, mBatches=1, mStateFul=False, lossFn='mae', modelOptimizer='adam'):\n",
    "    tsSplit = TimeSeriesSplit(n_splits=splits)\n",
    "    lstm_scores = []\n",
    "    for train_index, test_index in tsSplit.split(df):\n",
    "        scaler_train = MinMaxScaler(feature_range=(-1, 1))\n",
    "        scaler_test = MinMaxScaler(feature_range=(-1, 1))\n",
    "        train, test = df[0:len(train_index)], df[1+len(train_index):1+len(train_index)+len(test_index)]\n",
    "        train_scaled = scaler_train.fit_transform(train[df.columns])\n",
    "        train_scaled = pd.DataFrame(train_scaled, columns=df.columns)\n",
    "        test_scaled = scaler_test.fit_transform(test[df.columns])\n",
    "        test_scaled = pd.DataFrame(test_scaled, columns=df.columns)\n",
    "\n",
    "        X_train, y_train = prepareLSTMModelData(train_scaled, m_days)\n",
    "        X_test, y_test = prepareLSTMModelData(test_scaled, m_days)\n",
    "        test_dates = dates[1+len(train_index)+m_days:1+len(train_index)+len(test_index)]\n",
    "\n",
    "        print(\"X train {} and test {}\".format(X_train.shape, X_test.shape))\n",
    "        print(\"Y train {} and test {}\".format(y_train.shape, y_test.shape))\n",
    "        print(\"Test dates {}\".format(test_dates.shape))\n",
    "        model = Sequential()\n",
    "        if (mStateFul == True):\n",
    "            model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]),\\\n",
    "                    return_sequences=True, \\\n",
    "                    stateful=True, batch_size=mBatches))\n",
    "        else:\n",
    "            model.add(LSTM(neurons, input_shape=(X_train.shape[1], X_train.shape[2]),\\\n",
    "                       return_sequences=True))\n",
    "        #model.add(LSTM(20, return_sequences=True))\n",
    "        model.add(LSTM(neurons))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss=lossFn, optimizer=modelOptimizer, metrics=[rmse_metric])\n",
    "        print(model.summary())\n",
    "        history = None\n",
    "        for i in range(num_epochs):\n",
    "            history = model.fit(X_train, y_train, #validation_data=(X_test, y_test),\n",
    "                  epochs=1, batch_size=mBatches, verbose=2)\n",
    "            model.reset_states()\n",
    "        print(history.history.keys())\n",
    "        predicted = model.predict(X_test, batch_size=1)\n",
    "\n",
    "        y_test = y_test.reshape(-1,1)\n",
    "        print(\"Reshaped predicted {} and y_test {}\".format(predicted.shape, y_test.shape))\n",
    "\n",
    "        y_pred = scaler_test.inverse_transform(predicted)\n",
    "        y_pred_df = pd.DataFrame(y_pred, columns=[\"y_pred\"])\n",
    "        y_actual = scaler_test.inverse_transform(y_test)\n",
    "        y_actual_df = pd.DataFrame(y_actual, columns=[\"y\"])\n",
    "        labels_df = pd.concat([y_pred_df, y_actual_df], axis=1)\n",
    "        print(\"test_dates shape {} vs y_pred shape {} vs y_test shape {}\" \\\n",
    "              .format(test_dates.shape, y_pred.shape, y_test.shape))\n",
    "\n",
    "        print(labels_df[:5])\n",
    "        print(predicted[:5])\n",
    "        print(y_test[:5])\n",
    "\n",
    "        if ax is not None:\n",
    "            print(\"Plot graph here\")\n",
    "            cs.plot_graph(ax[len(lstm_scores)], test_dates, y_pred, y_actual)\n",
    "            # summarize history for loss\n",
    "            #ax[len(lstm_scores)].plot(history.history['rmse_metric'])\n",
    "            #ax[len(lstm_scores)].plot(history.history['val_rmse_metric'])\n",
    "\n",
    "            #ax[len(lstm_scores)].plot(history.history['mean_squared_error'])\n",
    "            #ax[len(lstm_scores)].plot(history.history['val_mean_squared_error'])\n",
    "            #         ax[len(lstm_scores)].title('model loss')\n",
    "            #         ax[len(lstm_scores)].ylabel('loss')\n",
    "            #         ax[len(lstm_scores)].xlabel('epoch')\n",
    "            #         ax[len(lstm_scores)].legend(['train', 'test'], loc='upper left')\n",
    "        lstm_scores.append(rmse_score(y_pred_df['y_pred'], y_actual_df['y']))\n",
    "    print(lstm_scores)\n",
    "    return lstm_scores\n",
    "\n",
    "def run_lstm(stock_data, split_count, M_history, N_predict):\n",
    "    plt.close('all')\n",
    "    fig, ax = plt.subplots(1, split_count, figsize=(14,8))\n",
    "    stock_frame = stock_data[:100]\n",
    "    stock_dates = stock_frame.index.values\n",
    "    validateLSTMModel(ax, stock_frame, M_history, N_predict, split_count, stock_dates, 32, 5, 20, False)\n",
    "    plt.show()\n",
    "\n",
    "def experiment_lstm_parameters(stock_data):\n",
    "    stock_frame = stock_data\n",
    "    stock_dates = stock_frame.index.values\n",
    "    dataSplits = 2\n",
    "    experiment_df = pd.DataFrame()\n",
    "    historyList = [14, 30, 60]\n",
    "    neuronList = [1, 5, 10, 30]\n",
    "    statefulList = [False, True]\n",
    "    epochList = [1, 10, 20, 30, 50]\n",
    "    lossFnList = ['mae', 'mse']\n",
    "    optimizerList = ['adam', 'sgd', 'rmsprop', 'adadelta']\n",
    "    batchSizeList = [1, 10, 30]\n",
    "    totalIterations = len(historyList)*len(neuronList)*len(statefulList)\n",
    "    totalIterations *= len(epochList)*len(lossFnList)*len(optimizerList)*len(batchSizeList)\n",
    "    i = 0\n",
    "    for history in historyList:\n",
    "        for neurons in neuronList:\n",
    "            for stateful in statefulList:\n",
    "                for epochs in epochList:\n",
    "                    for lossFunction in lossFnList:\n",
    "                        for optimizer in optimizerList:\n",
    "                            for batchSize in batchSizeList:\n",
    "                                if (batchSize > 1 and stateful is True):\n",
    "                                    continue\n",
    "                                expStr = \"{}-{}-{}-{}-{}-{}-{}\".format(history, stateful, neurons,\\\n",
    "                                                    epochs, lossFunction, optimizer, batchSize)\n",
    "                                print(expStr)\n",
    "                                i = i + 1\n",
    "                                print(\"Iteration {} of {}\".format(i, totalIterations))\n",
    "                                result = validateLSTMModel(None, stock_frame, history, 14, dataSplits, stock_dates, \\\n",
    "                                                 neurons, epochs, batchSize, stateful, lossFunction)\n",
    "                                experiment_df[expStr] = result\n",
    "                                experiment_df.to_csv(str(i)+\"_experiment.csv\", index=False)\n",
    "    experiment_df.to_csv('final_experiment_results.csv', index=False)\n",
    "\n",
    "def run_experiment():\n",
    "    stockdf = cs.get_stock_dataframe(stock_name, dateFrom = stock_start_date)\n",
    "    stockdf = stockdf[['Adj. Close']]\n",
    "    #run_lstm(stockdf, timeSeriesSplitCount, M_historical_days, N_predict_days)\n",
    "    #run_lstm(stockdf, 2, 10, N_predict_days)\n",
    "    experiment_lstm_parameters(stockdf)\n",
    "\n",
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:aind-dog]",
   "language": "python",
   "name": "conda-env-aind-dog-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
